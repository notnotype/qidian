import logging
import click

from urllib.parse import urljoin
from requests import get
from lxml.etree import HTML
from json import dumps, loads
from FontIconMappingTable import FontIconMappingTable, translate

from time import localtime

_get = get
logger = logging.Logger("main")
handler = logging.FileHandler(f"logs/"
                              f"{localtime().tm_year}-"
                              f"{localtime().tm_mon}-"
                              f"{localtime().tm_mday}-"
                              f"{localtime().tm_min}-"
                              f"{localtime().tm_min}.log",
                              encoding="utf-8")
formatter = logging.Formatter("[%(levelname)s]-[%(levelno)sè¡Œ]-%(message)s")
handler.setFormatter(formatter)
logger.addHandler(handler)

console = logging.StreamHandler()
console.setLevel(logging.INFO)

logger.addHandler(handler)
logger.addHandler(console)

TIMEOUT = None
HEADERS = ""
OUTFILE = "out.json"


# åŒ…è£…getæ–¹æ³•
def get(*args, **kwargs):
    retry = 0
    while retry <= 3:
        try:
            if TIMEOUT:
                kwargs["timeout"] = TIMEOUT
            if HEADERS:
                kwargs["headers"] = loads(HEADERS.replace("'", "\""))
            logger.info("[è·å–ç½‘é¡µ] {}".format(args[0]))
            return _get(*args, **kwargs)
        except Exception as e:
            logger.error("[è·å–ç½‘é¡µå¤±è´¥] " + str(e))
            retry += 1
    return None


def get_headers():
    return {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chr"
                          "ome/86.0.4240.111 Safari/537.36"}


def get_api(chan_id, sub_cata_id, page):
    url = f"https://www.qidian.com/all?chanId={chan_id}&subcataId={sub_cata_id}&orderId=&page={page}&style=" \
          f"2&pageSize=50&siteid=1&pubflag=0&hiddenField=0"
    return url


class OutFile:
    def __init__(self, filename: str):
        self.f = open(filename, "w+", encoding="utf8")

    def save(self, item: dict):
        self.f.write(dumps(item).encode().decode("unicode_escape") + "\n")
        self.f.flush()

    def close(self):
        self.f.close()


# noinspection PyBroadException
def get_detailed_info(novel_url) -> dict:
    novel_id = novel_url[novel_url.rindex("/") + 1:]
    resp = get(novel_url, headers=get_headers())
    html = HTML(resp.text)

    book_info = html.xpath("//div[@class='book-info ']")[0]

    item = {}

    # æ ‡ç­¾
    tag = [e.xpath("./text()")[0] for e in book_info[1]]

    # æè¿°
    intro = book_info[2].xpath("./text()")[0]

    # ç ´è§£å­—ä½“å›¾æ ‡åŠ å¯†
    fimt = FontIconMappingTable(html, get_headers())
    mapping_table = fimt.get_table()

    # æ¨è
    num = [translate(i, mapping_table) for i in book_info[3].xpath(".//em/span/text()")]
    unit = book_info[3].xpath(".//cite/text()")
    recommend = list(zip(num, unit))

    # è·å–è¯„è®º
    resp = get(f"https://book.qidian.com/ajax/comment/index?bookId={novel_id}&pageSize=15", headers=get_headers())
    resp_json = resp.json()

    rate = translate(resp_json["data"]["rate"], mapping_table)
    user_counts = translate(resp_json["data"]["userCount"], mapping_table)
    # è¿™ä¸ªåœ°æ–¹å–œæ¬¢æŠ¥é”™, ç°åœ¨ä¸æŠ¥é”™äº†,å˜¿å˜¿
    try:
        # å…ˆç”¨è€api, åœ¨å°è¯•æ–°api
        # è€api, å–œæ¬¢æŠ¥é”™
        logger.debug("ä½¿ç”¨è€api")
        chapter_counts = translate(html.xpath("//span[@id='J-catalogCount']/text()")[0], mapping_table)
    except Exception as e:
        logger.debug("è€apiå‡ºé”™ ä½¿ç”¨æ–°api åŸå› :")
        logger.exception(e, stacklevel=logging.DEBUG)
        chapter_counts = translate(get(f"https://book.qidian.com/ajax/book/category?bookId={novel_id}",
                                       headers=get_headers()).json()["data"]["chapterTotalCnt"], mapping_table)

    # æŠŠæ•°æ®æ·»åŠ åˆ°item
    item["tag"] = tag
    item["intro"] = intro
    item["recommend"] = recommend
    item["rate"] = rate
    item["user_counts"] = user_counts
    item["chapter_counts"] = chapter_counts
    return item


# noinspection PyBroadException
def _spider(chan_id, sub_cata_id, page):
    # ä¿¡ä»»getæ–¹æ³•ä¸ä¼šæŠ¥é”™
    resp = get(get_api(chan_id, sub_cata_id, page), headers=get_headers())

    # å¦‚æœ `æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹¦` åœ¨ç½‘é¡µé‡Œé¢, åˆ™è¿”å›
    if not resp or "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹¦" in resp.text:
        logger.info(f"çˆ¬è¡Œåˆ°åº•äº† [{chan_id}]")
        return None

    html = HTML(resp.text)
    novels = []

    # è§£ææ–‡æ¡£
    tbody = html.xpath("//tbody")[0]
    for tr in tbody:
        # æ¯ä¸€ä¸ªé¡¹ç›®çš„ä¿¡æ¯
        item = {}

        # ç±»åˆ«
        cata = (tr[0][0].xpath("./text()")[0], tr[0][-1].xpath("./text()")[0])
        # ä¹¦å
        name = tr[1][0].xpath("./text()")[0]
        # é“¾æ¥
        novel_url = urljoin("https://www.qidian.com/", tr[1][0].xpath(".//@href")[0])
        # è§£æid
        novel_id = novel_url[novel_url.rindex("/") + 1:]
        # è¿›å…¥ç®€ä»‹é¡µé¢è·å–ä¿¡æ¯

        try:
            detailed_info = get_detailed_info(novel_url).items()
        except Exception as e:
            logger.error(f"[æ•°æ®æŠ“å–é”™è¯¯] {name}")
            logger.exception(e)
            continue

        for key, value in detailed_info:
            item[key] = value

        # æœ€åä¸€ç« 
        last_chapter = tr[2][0].xpath("./text()")[0]
        # å­—æ•°
        # todo æ·»åŠ å•ä½
        '''
            <span class="total" xpath="1">
                <style>@font-face { font-family: sCAWJsOr; src: url('https://qidian.gtimg.com/qd_anti_spider/sCAWJsOr.eot?') format('eot'); src: url('https://qidian.gtimg.com/qd_anti_spider/sCAWJsOr.woff') format('woff'), url('https://qidian.gtimg.com/qd_anti_spider/sCAWJsOr.ttf') format('truetype'); } .sCAWJsOr { font-family: 'sCAWJsOr' !important;     display: initial !important; color: inherit !important; vertical-align: initial !important; }</style>
                <span class="sCAWJsOr">ğ˜œ’ğ˜œ”ğ˜œ™ğ˜œ•ğ˜œ™ğ˜œ™</span>ä¸‡
            </span>
        '''
        # word_counts = tr[3][0][-1].xpath("./text()")[0]
        # ä½œè€…
        author = tr[4][0].xpath("./text()")[0]
        update_date = tr[5].xpath("./text()")[0]

        # å°è£…æ•°æ®
        item["cata"] = cata
        item["name"] = name
        item["last_chapter"] = last_chapter
        # item["word_count"] = word_counts
        item["author"] = author
        item["update_date"] = update_date
        item["novel_id"] = novel_id

        novels.append(item)
        outfile.save(item)

        logger.info("[å¯¼å‡ºæ•°æ®] {}-{}-{}-{} ...".format(
            item["novel_id"],
            item["name"],
            item["author"],
            item["update_date"]
        ))
    return novels


# ä¸»é€»è¾‘
def _main(chan_id, sub_cata_id, headers=None, timeout=None, outfile="out.json"):
    global TIMEOUT
    global HEADERS
    global OUTFILE
    TIMEOUT = timeout
    HEADERS = headers
    OUTFILE = outfile
    for i in range(1, 3):
        _spider(chan_id, sub_cata_id, str(i))


# åŒ…è£…click
# clickç»„
@click.group()
def main():
    pass


# click spiderå‘½ä»¤
@click.command()
@click.option("--chan-id", "-ci", prompt="è¾“å…¥å¤§ç±»id", help="å¤§ç±»id")
@click.option("--sub-cata-id", "-sci", prompt="è¾“å…¥å°ç±»id", help="å°ç±»id")
@click.option("--headers", "-h", help="æºå¸¦è¯·æ±‚å¤´")
@click.option("--timeout", "-t", default=15.0, help="è®¾ç½®è¯·æ±‚è¶…æ—¶æ—¶é—´")
@click.option("--outfile", "-o", default="out.json", help="è®¾ç½®è¾“å‡ºæ–‡ä»¶")
@click.option("--fromfile", "-f", help="ä»æ–‡ä»¶åŠ è½½æ•°æ®")
@click.option("--debug", "-d", help="å¯ç”¨è°ƒè¯•", default=False)
def spider(chan_id, sub_cata_id, headers=None, timeout=None, outfile="out.json", fromfile=None, debug=False):
    """çˆ¬å–å¤§ç±»chan_id, å°ç±»sub_cata_idä¸‹çš„æ‰€æœ‰æ•°æ®"""
    if debug:
        logger.setLevel(logging.DEBUG)
        console.setLevel(logging.DEBUG)
    logger.debug(f"[æ¥å—å‚æ•°]: {TIMEOUT}, {HEADERS}, {OUTFILE}, {debug}")
    if not fromfile:
        _main(chan_id, sub_cata_id, headers, timeout, outfile)
        return
    else:
        with open(fromfile, "r") as f:
            for line in f:
                a, b = line.split(" ")
                _main(a.strip(), b.strip(), headers, timeout, outfile)


main.add_command(spider)
if __name__ == '__main__':
    outfile = OutFile(OUTFILE)
    # r = spider()
    # r = get_detailed_info("https://book.qidian.com/info/1115277")
    # r = get("http://www.baidu.com")
    # logger.info(r)
    # main()
    # outfile.close()

    r = get_detailed_info("https://book.qidian.com/info/1003306811")
    print(r)
